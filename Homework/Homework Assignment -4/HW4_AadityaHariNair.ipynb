{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c086f9-b1cd-4380-ba40-aa4cb7cc8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the main dataset\n",
    "train_x = pd.read_csv('train_x.csv')\n",
    "\n",
    "# Load the additional scale datasets\n",
    "st_scale = pd.read_csv('ST-scale.csv', skiprows=2)\n",
    "t_scale = pd.read_csv('T-scale.csv', skiprows=2)\n",
    "z_scale = pd.read_csv('Z-scale.csv', skiprows=2)\n",
    "dpps = pd.read_csv(\"DPPS.csv\", skiprows=2)\n",
    "whim = pd.read_csv(\"MS-WHIM.csv\", skiprows=2)\n",
    "phys = pd.read_csv(\"Physical.csv\", skiprows=2)\n",
    "vhse = pd.read_csv(\"VHSE-scale.csv\", skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d35375d-a7d0-4340-bab2-61350a3f7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping dictionaries for each scale\n",
    "st_dict = st_scale.set_index('AA_1').to_dict('index')#\n",
    "t_dict = t_scale.set_index('AA_1').to_dict('index')#\n",
    "z_dict = z_scale.set_index('AA_1').to_dict('index')#\n",
    "dpps_dict = dpps.set_index('AA_1').to_dict('index')#\n",
    "whim_dict = whim.set_index('AA_1').to_dict('index')#\n",
    "phys_dict = phys.set_index('AA_1').to_dict('index')\n",
    "vhse_dict = vhse.set_index('AA_1').to_dict('index')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174df3ec-8b59-4b4b-a003-fdf8451b1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_sequence(sequence):\n",
    "    enriched_sequence = []\n",
    "    for aa in sequence:\n",
    "        properties = {}\n",
    "        if aa in st_dict:\n",
    "            properties.update({f'ST{i}': st_dict[aa][f'ST{i}'] for i in range(1, 9)})\n",
    "        if aa in t_dict:\n",
    "            properties.update({f'T{i}': t_dict[aa][f'T{i}'] for i in range(1, 6)})\n",
    "        if aa in z_dict:\n",
    "            properties.update({f'Z{i}': z_dict[aa][f'Z({i})'] for i in range(1, 4)})\n",
    "        if aa in dpps_dict:\n",
    "            properties.update({f'D{i}': dpps_dict[aa][f'D{i}'] for i in range(1, 11)})\n",
    "        if aa in vhse_dict:\n",
    "            properties.update({f'VHSE{i}': vhse_dict[aa][f'VHSE{i}'] for i in range(1, 9)})\n",
    "        if aa in whim_dict:\n",
    "            properties.update({f'WHIM{i}': whim_dict[aa][f'{i}'] for i in range(1,4)})\n",
    "        if aa in phys_dict:\n",
    "            properties.update({f'{i}': phys_dict[aa][f'{i}'] for i in [\"Vol\", \"Hydro\"]})\n",
    "        enriched_sequence.append((aa, properties))\n",
    "    return enriched_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d303dacf-d211-41bc-a9a5-467a8df2c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the enrichment function to the 'ConstructedAASeq_cln' column\n",
    "train_x['EnrichedSequence'] = train_x['ConstructedAASeq_cln'].apply(enrich_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c679e-7c9e-4481-93af-a09e14c18f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST1\n",
      "ST2\n",
      "ST3\n",
      "ST4\n",
      "ST5\n",
      "ST6\n",
      "ST7\n",
      "ST8\n",
      "T1\n",
      "T2\n",
      "T3\n",
      "T4\n",
      "T5\n",
      "Z1\n",
      "Z2\n",
      "Z3\n",
      "D1\n",
      "D2\n",
      "D3\n",
      "D4\n",
      "D5\n",
      "D6\n",
      "D7\n",
      "D8\n",
      "D9\n",
      "D10\n",
      "VHSE1\n"
     ]
    }
   ],
   "source": [
    "# Create new columns for each property\n",
    "all_properties = ['ST1', 'ST2', 'ST3', 'ST4', 'ST5', 'ST6', 'ST7', 'ST8', \n",
    "                  'T1', 'T2', 'T3', 'T4', 'T5', \n",
    "                  'Z1', 'Z2', 'Z3',\n",
    "                 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10',\n",
    "                 'VHSE1', 'VHSE2', 'VHSE3', 'VHSE4', 'VHSE5', 'VHSE6', 'VHSE7', 'VHSE8',\n",
    "                'WHIM1', 'WHIM2', 'WHIM3','Vol', 'Hydro']\n",
    "for prop in all_properties:\n",
    "    train_x[f'Mean_{prop}'] = train_x['EnrichedSequence'].apply(lambda seq: np.mean([float(aa[1].get(prop, 0)) for aa in seq]))\n",
    "    train_x[f'Std_{prop}'] = train_x['EnrichedSequence'].apply(lambda seq: np.std([float(aa[1].get(prop, 0)) for aa in seq]))\n",
    "    print(prop)\n",
    "# Remove the temporary 'EnrichedSequence' column\n",
    "train_x = train_x.drop('EnrichedSequence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d9244-b92f-43a6-9804-b8e36d7b6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"train_y.csv\")\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da286947-76c8-4adb-89a8-631676b05295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the enriched dataset\n",
    "train_x = train_x.drop('Unnamed: 0', axis = 1)\n",
    "train_x = train_x.drop('ConstructedAASeq_cln', axis = 1)\n",
    "train_x = train_x.drop('Id', axis = 1)\n",
    "Y = train_y.Brightness_Class\n",
    "train_x.info()\n",
    "train_x.to_csv('enriched_train_x.csv', index=False)\n",
    "print(\"Dataset enrichment complete. New file saved as 'enriched_train_x.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6400f-cd09-4556-9eec-6597b910a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cf3cd-f59a-4d5a-a245-04d0a3fd104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "whim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0edfa-9b1a-4dcd-bcb8-e484be4149a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "only1 = []\n",
    "for k in train_x.columns:\n",
    "    if train_x[k].nunique() != train_x.shape[0]:\n",
    "        only1.append(train_x[k].nunique())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427f051-735b-40c4-9c3e-09b17122680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_x.columns:\n",
    "    if train_x[i].isna().sum()!=0:\n",
    "        print(i,train_x[i].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1f00c-be91-4019-b8dc-f6fe01178101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "trainn_x = s.fit_transform(train_x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainn_x, Y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a3b6f-1127-437b-9595-9208067344b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(X_train, y_train)\n",
    "predict = logr.predict(X_test)\n",
    "logr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edb9cf-0052-4f07-9aa4-9befa5e595cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "# Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Get the best score\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best cross-validation score:\", best_score)\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test set score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291ce61-1e3b-433e-b894-fc4db8dc77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc33227-bfbf-4683-beaa-70cc0f65bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = train_x.iloc[:, 1:16].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(130, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(train_x.iloc[:, 1:16].corr(), vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b44ce1b-4876-42c5-b2a6-513154fadd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(best_model,f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a2546ec-f2fb-41cf-97d4-8c51020a6323",
   "metadata": {},
   "source": [
    "test_x = pd.read_csv(\"test_X.csv\")\n",
    "test_x['EnrichedSequence'] = test_x['ConstructedAASeq_cln'].apply(enrich_sequence)\n",
    "for prop in all_properties:\n",
    "    test_x[f'Mean_{prop}'] = test_x['EnrichedSequence'].apply(lambda seq: np.mean([float(aa[1].get(prop, 0)) for aa in seq]))\n",
    "    test_x[f'Std_{prop}'] = test_x['EnrichedSequence'].apply(lambda seq: np.std([float(aa[1].get(prop, 0)) for aa in seq]))\n",
    "    print(prop)\n",
    "# Remove the temporary 'EnrichedSequence' column\n",
    "test_x = test_x.drop('EnrichedSequence', axis=1)\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70260e7c-1370-4a99-b8fe-bc14c6127bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.to_csv(\"Enriched_test_x.csv\", index = False)\n",
    "test_x.info()\n",
    "id = test_x.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe3917-c993-44e0-8d28-842290f8c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.drop('ConstructedAASeq_cln', axis = 1)\n",
    "test_x = test_x.drop('Id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79c121-1169-4c19-8c5f-e24df2fd6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "test_x = s.fit_transform(test_x)\n",
    "logr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ece53-03b4-45c8-987d-0eb4bf790b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf3fc3-e59e-46e8-8afc-f96c8e9c8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"Id\": id, \"Brightness_Class\":y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08394c1-4dc7-4b65-9aeb-b34943c179c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da9eb08-7436-4ee9-942b-a91d620c03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
